{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import lingam\n",
    "from lingam.utils import make_dot\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, KernelCenterer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit.aqua import QuantumInstance\n",
    "from qiskit.ignis.mitigation.measurement import (complete_meas_cal,CompleteMeasFitter)\n",
    "from qiskit import *\n",
    "from qiskit.tools.visualization import *\n",
    "from qiskit.circuit.library import *\n",
    "from qiskit.providers.aer import QasmSimulator, StatevectorSimulator, UnitarySimulator\n",
    "from qiskit import IBMQ, QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit import execute, Aer\n",
    "from qiskit.qasm import pi\n",
    "from qiskit.tools.visualization import plot_histogram, circuit_drawer\n",
    "\n",
    "from typing import cast, Dict, Iterator, List, Union\n",
    "from cirq import *\n",
    "import cirq\n",
    "from cirq import circuits, ops, protocols, linalg\n",
    "from cirq.sim import density_matrix_utils\n",
    "from cirq import DensityMatrixSimulator\n",
    "from cirq import DensityMatrixStepResult\n",
    "from cirqqulacs import QulacsSimulator\n",
    "import qulacs\n",
    "from cirq.google import *\n",
    "from cirq.contrib.svg import SVGCircuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing available devices in IBMQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBMQ.save_account(TOKEN)\n",
    "IBMQ.load_account() \n",
    "IBMQ.providers()    \n",
    "ibmq_provider = IBMQ.get_provider()\n",
    "backend_sim = ibmq_provider.backends()[] # Select the device to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tanh-shrink function\"\"\"\n",
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "def func_one(x):\n",
    "    return x - tanh(x)\n",
    "def func_two(x1, x2):\n",
    "    return (x1 - tanh(x1))*(x2 - tanh(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"quantum kernel using cirq and qulacs\"\"\"\n",
    "#ring connection\n",
    "def quantum_kernel_cirq_ring(bn, n_samples, data_x, depth):\n",
    "    \n",
    "    result_gram_mat = np.eye(n_samples)\n",
    "    \n",
    "    pair_list = []\n",
    "    for pair in itertools.combinations(list(range(n_samples)), 2):\n",
    "        pair_list.append(list(pair))\n",
    "    \n",
    "    #scaling and standardization\n",
    "    x_standardize = preprocessing.scale(data_x)\n",
    "    x_input = np.array([2*x_standardize for i in range(bn)])\n",
    "    \n",
    "    #calculations for Gram matrix\n",
    "    for j in range(len(pair_list)):\n",
    "        q = [GridQubit(i, 0) for i in range(bn)]\n",
    "        \n",
    "        #IQP circuit\n",
    "        def IQP_circuit(qci, bn, input_data, rep):\n",
    "            for _ in range(rep):\n",
    "                #Hゲートを掛ける\n",
    "                qci.append(H.on_each(q))\n",
    "                for i in range(bn):\n",
    "                    qci.append(cirq.ZPowGate(exponent = func_one(input_data[i]))(q[i]))\n",
    "                for i in range(bn):\n",
    "                    if i == (bn-1):\n",
    "                        qci.append(cirq.CZPowGate(exponent = func_two(input_data[bn-1], input_data[0]))(q[bn-1], q[0]))\n",
    "                    else:\n",
    "                        qci.append(cirq.CZPowGate(exponent = func_two(input_data[i], input_data[i+1]))(q[i], q[i+1]))\n",
    "        \n",
    "        #First half of the circuit\n",
    "        qc_cirq = Circuit()\n",
    "        IQP_circuit(qci = qc_cirq, bn = bn, input_data = x_input[:, pair_list[j][0]], rep = depth)\n",
    "        result_1 = QulacsSimulator().simulate(qc_cirq)\n",
    "        #Second half of the circuit\n",
    "        qcd_cirq = Circuit()\n",
    "        IQP_circuit(qci = qcd_cirq, bn = bn, input_data = x_input[:, pair_list[j][1]], rep = depth)\n",
    "        result_2 = QulacsSimulator().simulate(qcd_cirq)\n",
    "        #Calculations for Gram matrix using inner product\n",
    "        state_1 = result_1._final_simulator_state.reshape(1,-1)\n",
    "        state_2 = result_2._final_simulator_state.reshape(1,-1)\n",
    "        result_kernel = abs((np.conjugate(state_1) @ state_2.T)[0][0])**2\n",
    "        result_gram_mat[pair_list[j][0], pair_list[j][1]] = result_kernel\n",
    "        \n",
    "    kernel_gram_mat = result_gram_mat + result_gram_mat.T - np.diag(result_gram_mat.diagonal())\n",
    "    return kernel_gram_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"quantum kernel using cirq and qulacs\"\"\"\n",
    "#linear connection\n",
    "def quantum_kernel_cirq_linear(bn, n_samples, data_x, depth):\n",
    "    \n",
    "    result_gram_mat = np.eye(n_samples)\n",
    "    \n",
    "    pair_list = []\n",
    "    for pair in itertools.combinations(list(range(n_samples)), 2):\n",
    "        pair_list.append(list(pair))\n",
    "    \n",
    "    #scaling and standardization\n",
    "    x_standardize = preprocessing.scale(data_x)\n",
    "    x_input = np.array([2*x_standardize for i in range(bn)])\n",
    "    \n",
    "    #calculations for Gram matrix\n",
    "    for j in range(len(pair_list)):\n",
    "        q = [GridQubit(i, 0) for i in range(bn)]\n",
    "        \n",
    "        #IQP circuit\n",
    "        def IQP_circuit(qci, bn, input_data, rep):\n",
    "            for _ in range(rep):\n",
    "                qci.append(H.on_each(q))\n",
    "                for i in range(bn):\n",
    "                    qci.append(cirq.ZPowGate(exponent = func_one(input_data[i]))(q[i]))\n",
    "                for i in range(bn-1):\n",
    "                    qci.append(cirq.CZPowGate(exponent = func_two(input_data[i], input_data[i+1]))(q[i], q[i+1]))\n",
    "        \n",
    "        #First half of the circuit\n",
    "        qc_cirq = Circuit()\n",
    "        IQP_circuit(qci = qc_cirq, bn = bn, input_data = x_input[:, pair_list[j][0]], rep = depth)\n",
    "        result_1 = QulacsSimulator().simulate(qc_cirq)\n",
    "        #Second half of the circuit\n",
    "        qcd_cirq = Circuit()\n",
    "        IQP_circuit(qci = qcd_cirq, bn = bn, input_data = x_input[:, pair_list[j][1]], rep = depth)\n",
    "        result_2 = QulacsSimulator().simulate(qcd_cirq)\n",
    "        #Calculations for Gram matrix using inner product\n",
    "        state_1 = result_1._final_simulator_state.reshape(1,-1)\n",
    "        state_2 = result_2._final_simulator_state.reshape(1,-1)\n",
    "        result_kernel = abs((np.conjugate(state_1) @ state_2.T)[0][0])**2\n",
    "        result_gram_mat[pair_list[j][0], pair_list[j][1]] = result_kernel\n",
    "        \n",
    "    kernel_gram_mat = result_gram_mat + result_gram_mat.T - np.diag(result_gram_mat.diagonal())\n",
    "    return kernel_gram_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"quantum kernel using Qiskit with error mitigation\"\"\"\n",
    "#linear connection\n",
    "def quantum_kernel_qiskit_IBMQ_sep_mitigated(bn, n_samples, data_x, depth):\n",
    "    #Preparation for error mitigation\n",
    "    qr = QuantumRegister(bn)\n",
    "    meas_calibs, state_labels = complete_meas_cal(qr=qr, circlabel='mcal')\n",
    "    miti_r = execute(meas_calibs, backend=backend_sim, initial_layout=[0,1,4,7],optimization_level = 3, shots=8192)\n",
    "    cal_results = miti_r.result()\n",
    "    meas_fitter = CompleteMeasFitter(cal_results, state_labels, circlabel='mcal')\n",
    "    meas_filter = meas_fitter.filter\n",
    "    \n",
    "    result_gram_mat = np.eye(n_samples)\n",
    "    pair_list = []\n",
    "    for pair in itertools.combinations(list(range(n_samples)), 2):\n",
    "        pair_list.append(list(pair))\n",
    "    \n",
    "    #job list\n",
    "    job_all = []\n",
    "    \n",
    "    #scaling and standardization\n",
    "    x_standardize = preprocessing.scale(data_x)\n",
    "    x_input = np.array([2*x_standardize for i in range(bn)])\n",
    "    \n",
    "    #calculations for Gram matrix\n",
    "    for j in range(len(pair_list)):\n",
    "        #quantum bits\n",
    "        q = QuantumRegister(bn, \"q\")\n",
    "        c = ClassicalRegister(bn,\"c\")\n",
    "\n",
    "        #IQP circuit\n",
    "        def IQP_circuit(qci, bn, input_data, rep):\n",
    "            for _ in range(rep):\n",
    "                for i in range(bn):\n",
    "                    qci.h(q[i])\n",
    "                for i in range(bn):\n",
    "                    qci.u1(math.pi*func_one(input_data[i]), q[i])\n",
    "                for i in range(bn-1):\n",
    "                    qci.cu1(math.pi*func_two(input_data[i], input_data[i+1]), q[i], q[i+1])\n",
    "\n",
    "        #First half of the circuit\n",
    "        qc = QuantumCircuit(q, c)\n",
    "        IQP_circuit(qci = qc, bn = bn, input_data = x_input[:, pair_list[j][0]], rep = depth)\n",
    "        #Second half of the circuit\n",
    "        qcd = QuantumCircuit(q, c)\n",
    "        IQP_circuit(qci = qcd, bn = bn, input_data = x_input[:, pair_list[j][1]], rep = depth)\n",
    "        qcd = qcd\n",
    "        qcd_inverse = qcd.inverse()\n",
    "\n",
    "        #Combine the circuits and perform the inversion test\n",
    "        qc = qc.compose(qcd_inverse)\n",
    "        for i in range(bn):\n",
    "            qc.measure(q[bn-1-i], c[i])\n",
    "        job_all.append(qc)\n",
    "        \n",
    "    #Number of circuits per job\n",
    "    sep_num = 300\n",
    "    def split_list(l, n):\n",
    "        for idx in range(0, len(l), n):\n",
    "            yield l[idx:idx + n]\n",
    "    \n",
    "    job_sep_list = list(split_list(job_all, sep_num))\n",
    "    rc_list = []\n",
    "    #Perform calculations for each job\n",
    "    #Set the number of qubits to use and the number of shots\n",
    "    for i in range(len(job_sep_list)):\n",
    "        r = execute(job_sep_list[i], backend_sim,initial_layout=[0,1,4,7],optimization_level=3,shots=8192).result()\n",
    "        mitigated_r = meas_filter.apply(r)\n",
    "        for k in range(len(job_sep_list[i])):\n",
    "            r_count = mitigated_r.get_counts(k)\n",
    "            rc_list.append(r_count)\n",
    "        \n",
    "    for j in range(len(pair_list)):\n",
    "        rc = rc_list[j]\n",
    "        rc.setdefault('0'*bn, 0)\n",
    "        #Estimate quantum kernel\n",
    "        result_kernel = rc[\"0\"*bn]/sum(rc.values())\n",
    "        result_gram_mat[pair_list[j][0], pair_list[j][1]] = result_kernel\n",
    "        \n",
    "    kernel_gram_mat = result_gram_mat + result_gram_mat.T - np.diag(result_gram_mat.diagonal())\n",
    "    return kernel_gram_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three cells are the source code for qLiNGAM, created by modifying the source code at the URL:<br>\n",
    "https://github.com/cdt15/lingam <br>\n",
    "The license for the above is as follows. <br>\n",
    "\n",
    "\n",
    "Copyright (c) 2019 T.Ikeuchi, G.Haraoka, M.Ide, W.Kurebayashi, S.Shimizu\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "from sklearn.utils import check_array, resample\n",
    "\n",
    "\n",
    "class BootstrapMixin():\n",
    "    def bootstrap(self, X, n_sampling):\n",
    "        # Check parameters\n",
    "        X = check_array(X)\n",
    "\n",
    "        if isinstance(n_sampling, (numbers.Integral, np.integer)):\n",
    "            if not 0 < n_sampling:\n",
    "                raise ValueError(\n",
    "                    'n_sampling must be an integer greater than 0.')\n",
    "        else:\n",
    "            raise ValueError('n_sampling must be an integer greater than 0.')\n",
    "\n",
    "        # Bootstrapping\n",
    "        adjacency_matrices = []\n",
    "        for _ in range(n_sampling):\n",
    "            model = self.fit(resample(X))\n",
    "            adjacency_matrices.append(model.adjacency_matrix_)\n",
    "        return BootstrapResult(adjacency_matrices)\n",
    "\n",
    "\n",
    "class BootstrapResult(object):\n",
    "    def __init__(self, adjacency_matrices):\n",
    "        self._adjacency_matrices = adjacency_matrices\n",
    "\n",
    "    @property\n",
    "    def adjacency_matrices_(self):\n",
    "        \n",
    "        return self._adjacency_matrices\n",
    "\n",
    "    def get_causal_direction_counts(self, n_directions=None, min_causal_effect=None, split_by_causal_effect_sign=False):\n",
    "        # Check parameters\n",
    "        if isinstance(n_directions, (numbers.Integral, np.integer)):\n",
    "            if not 0 < n_directions:\n",
    "                raise ValueError(\n",
    "                    'n_directions must be an integer greater than 0')\n",
    "        elif n_directions is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('n_directions must be an integer greater than 0')\n",
    "\n",
    "        if min_causal_effect is None:\n",
    "            min_causal_effect = 0.0\n",
    "        else:\n",
    "            if not 0.0 < min_causal_effect:\n",
    "                raise ValueError(\n",
    "                    'min_causal_effect must be an value greater than 0.')\n",
    "\n",
    "        # Count causal directions\n",
    "        directions = []\n",
    "        for am in self._adjacency_matrices:\n",
    "            direction = np.array(np.where(np.abs(am) > min_causal_effect))\n",
    "            if split_by_causal_effect_sign:\n",
    "                signs = np.array([np.sign(am[i][j])\n",
    "                                  for i, j in direction.T]).astype('int64').T\n",
    "                direction = np.vstack([direction, signs])\n",
    "            directions.append(direction.T)\n",
    "        directions = np.concatenate(directions)\n",
    "\n",
    "        if len(directions) == 0:\n",
    "            cdc = {'from': [], 'to': [], 'count': []}\n",
    "            if split_by_causal_effect_sign:\n",
    "                cdc['sign'] = []\n",
    "            return cdc\n",
    "\n",
    "        directions, counts = np.unique(directions, axis=0, return_counts=True)\n",
    "        sort_order = np.argsort(-counts)\n",
    "        sort_order = sort_order[:n_directions] if n_directions is not None else sort_order\n",
    "        counts = counts[sort_order]\n",
    "        directions = directions[sort_order]\n",
    "\n",
    "        cdc = {\n",
    "            'from': directions[:, 1].tolist(),\n",
    "            'to': directions[:, 0].tolist(),\n",
    "            'count': counts.tolist()\n",
    "        }\n",
    "        if split_by_causal_effect_sign:\n",
    "            cdc['sign'] = directions[:, 2].tolist()\n",
    "\n",
    "        return cdc\n",
    "\n",
    "    def get_directed_acyclic_graph_counts(self, n_dags=None, min_causal_effect=None, split_by_causal_effect_sign=False):\n",
    "        # Check parameters\n",
    "        if isinstance(n_dags, (numbers.Integral, np.integer)):\n",
    "            if not 0 < n_dags:\n",
    "                raise ValueError('n_dags must be an integer greater than 0')\n",
    "        elif n_dags is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('n_dags must be an integer greater than 0')\n",
    "\n",
    "        if min_causal_effect is None:\n",
    "            min_causal_effect = 0.0\n",
    "        else:\n",
    "            if not 0.0 < min_causal_effect:\n",
    "                raise ValueError(\n",
    "                    'min_causal_effect must be an value greater than 0.')\n",
    "\n",
    "        # Count directed acyclic graphs\n",
    "        dags = []\n",
    "        for am in self._adjacency_matrices:\n",
    "            dag = np.abs(am) > min_causal_effect\n",
    "            if split_by_causal_effect_sign:\n",
    "                direction = np.array(np.where(dag))\n",
    "                signs = np.zeros_like(dag).astype('int64')\n",
    "                for i, j in direction.T:\n",
    "                    signs[i][j] = np.sign(am[i][j]).astype('int64')\n",
    "                dag = signs\n",
    "            dags.append(dag)\n",
    "\n",
    "        dags, counts = np.unique(dags, axis=0, return_counts=True)\n",
    "        sort_order = np.argsort(-counts)\n",
    "        sort_order = sort_order[:n_dags] if n_dags is not None else sort_order\n",
    "        counts = counts[sort_order]\n",
    "        dags = dags[sort_order]\n",
    "\n",
    "        if split_by_causal_effect_sign:\n",
    "            dags = [{\n",
    "                'from': np.where(dag)[1].tolist(),\n",
    "                'to': np.where(dag)[0].tolist(),\n",
    "                'sign': [dag[i][j] for i, j in np.array(np.where(dag)).T]} for dag in dags]\n",
    "        else:\n",
    "            dags = [{\n",
    "                'from': np.where(dag)[1].tolist(),\n",
    "                'to': np.where(dag)[0].tolist()} for dag in dags]\n",
    "\n",
    "        return {\n",
    "            'dag': dags,\n",
    "            'count': counts.tolist()\n",
    "        }\n",
    "\n",
    "    def get_probabilities(self, min_causal_effect=None):\n",
    "        # check parameters\n",
    "        if min_causal_effect is None:\n",
    "            min_causal_effect = 0.0\n",
    "        else:\n",
    "            if not 0.0 < min_causal_effect:\n",
    "                raise ValueError(\n",
    "                    'min_causal_effect must be an value greater than 0.')\n",
    "\n",
    "        shape = self._adjacency_matrices[0].shape\n",
    "        bp = np.zeros(shape)\n",
    "        for B in self._adjacency_matrices:\n",
    "            bp += np.where(np.abs(B) > min_causal_effect, 1, 0)\n",
    "        bp = bp/len(self._adjacency_matrices)\n",
    "\n",
    "        if int(shape[1]/shape[0]) == 1:\n",
    "            return bp\n",
    "        else:\n",
    "            return np.hsplit(bp, int(shape[1]/shape[0]))\n",
    "\n",
    "\n",
    "class LongitudinalBootstrapResult(object):\n",
    "    \n",
    "    def __init__(self, adjacency_matrices, n_timepoints):\n",
    "        \n",
    "        self._adjacency_matrices = adjacency_matrices\n",
    "        self._n_timepoints = n_timepoints\n",
    "\n",
    "    @property\n",
    "    def adjacency_matrices_(self):\n",
    "        \n",
    "        return self._adjacency_matrices\n",
    "\n",
    "    def get_causal_direction_counts(self, n_directions=None, min_causal_effect=None, split_by_causal_effect_sign=False):\n",
    "        \n",
    "        # Check parameters\n",
    "        if isinstance(n_directions, (numbers.Integral, np.integer)):\n",
    "            if not 0 < n_directions:\n",
    "                raise ValueError(\n",
    "                    'n_directions must be an integer greater than 0')\n",
    "        elif n_directions is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('n_directions must be an integer greater than 0')\n",
    "\n",
    "        if min_causal_effect is None:\n",
    "            min_causal_effect = 0.0\n",
    "        else:\n",
    "            if not 0.0 < min_causal_effect:\n",
    "                raise ValueError(\n",
    "                    'min_causal_effect must be an value greater than 0.')\n",
    "\n",
    "        # Count causal directions\n",
    "        cdc_list = []\n",
    "        for t in range(self._n_timepoints):\n",
    "\n",
    "            directions = []\n",
    "            for m in self._adjacency_matrices:\n",
    "                am = np.concatenate([*m[t]], axis=1)\n",
    "                direction = np.array(np.where(np.abs(am) > min_causal_effect))\n",
    "                if split_by_causal_effect_sign:\n",
    "                    signs = np.array([np.sign(am[i][j])\n",
    "                                      for i, j in direction.T]).astype('int64').T\n",
    "                    direction = np.vstack([direction, signs])\n",
    "                directions.append(direction.T)\n",
    "            directions = np.concatenate(directions)\n",
    "\n",
    "            if len(directions) == 0:\n",
    "                cdc = {'from': [], 'to': [], 'count': []}\n",
    "                if split_by_causal_effect_sign:\n",
    "                    cdc['sign'] = []\n",
    "                cdc_list.append(cdc)\n",
    "                continue\n",
    "\n",
    "            directions, counts = np.unique(\n",
    "                directions, axis=0, return_counts=True)\n",
    "            sort_order = np.argsort(-counts)\n",
    "            sort_order = sort_order[:n_directions] if n_directions is not None else sort_order\n",
    "            counts = counts[sort_order]\n",
    "            directions = directions[sort_order]\n",
    "\n",
    "            cdc = {\n",
    "                'from': directions[:, 1].tolist(),\n",
    "                'to': directions[:, 0].tolist(),\n",
    "                'count': counts.tolist()\n",
    "            }\n",
    "            if split_by_causal_effect_sign:\n",
    "                cdc['sign'] = directions[:, 2].tolist()\n",
    "\n",
    "            cdc_list.append(cdc)\n",
    "\n",
    "        return cdc_list\n",
    "\n",
    "    def get_directed_acyclic_graph_counts(self, n_dags=None, min_causal_effect=None, split_by_causal_effect_sign=False):\n",
    "        \n",
    "        # Check parameters\n",
    "        if isinstance(n_dags, (numbers.Integral, np.integer)):\n",
    "            if not 0 < n_dags:\n",
    "                raise ValueError('n_dags must be an integer greater than 0')\n",
    "        elif n_dags is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('n_dags must be an integer greater than 0')\n",
    "\n",
    "        if min_causal_effect is None:\n",
    "            min_causal_effect = 0.0\n",
    "        else:\n",
    "            if not 0.0 < min_causal_effect:\n",
    "                raise ValueError(\n",
    "                    'min_causal_effect must be an value greater than 0.')\n",
    "\n",
    "        # Count directed acyclic graphs\n",
    "        dagc_list = []\n",
    "        for t in range(self._n_timepoints):\n",
    "\n",
    "            dags = []\n",
    "            for m in self._adjacency_matrices:\n",
    "                am = np.concatenate([*m[t]], axis=1)\n",
    "\n",
    "                dag = np.abs(am) > min_causal_effect\n",
    "                if split_by_causal_effect_sign:\n",
    "                    direction = np.array(np.where(dag))\n",
    "                    signs = np.zeros_like(dag).astype('int64')\n",
    "                    for i, j in direction.T:\n",
    "                        signs[i][j] = np.sign(am[i][j]).astype('int64')\n",
    "                    dag = signs\n",
    "                dags.append(dag)\n",
    "\n",
    "            dags, counts = np.unique(dags, axis=0, return_counts=True)\n",
    "            sort_order = np.argsort(-counts)\n",
    "            sort_order = sort_order[:n_dags] if n_dags is not None else sort_order\n",
    "            counts = counts[sort_order]\n",
    "            dags = dags[sort_order]\n",
    "\n",
    "            if split_by_causal_effect_sign:\n",
    "                dags = [{\n",
    "                    'from': np.where(dag)[1].tolist(),\n",
    "                    'to': np.where(dag)[0].tolist(),\n",
    "                    'sign': [dag[i][j] for i, j in np.array(np.where(dag)).T]} for dag in dags]\n",
    "            else:\n",
    "                dags = [{\n",
    "                    'from': np.where(dag)[1].tolist(),\n",
    "                    'to': np.where(dag)[0].tolist()} for dag in dags]\n",
    "\n",
    "            dagc_list.append({\n",
    "                'dag': dags,\n",
    "                'count': counts.tolist()\n",
    "            })\n",
    "\n",
    "        return dagc_list\n",
    "\n",
    "    def get_probabilities(self, min_causal_effect=None):\n",
    "        \n",
    "        # check parameters\n",
    "        if min_causal_effect is None:\n",
    "            min_causal_effect = 0.0\n",
    "        else:\n",
    "            if not 0.0 < min_causal_effect:\n",
    "                raise ValueError(\n",
    "                    'min_causal_effect must be an value greater than 0.')\n",
    "\n",
    "        prob = np.zeros(self._adjacency_matrices[0].shape)\n",
    "        for adj_mat in self._adjacency_matrices:\n",
    "            prob += np.where(np.abs(adj_mat) > min_causal_effect, 1, 0)\n",
    "        prob = prob/len(self._adjacency_matrices)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn.linear_model import LassoLarsIC, LinearRegression\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "class _BaseLiNGAM(BootstrapMixin, metaclass=ABCMeta):\n",
    "\n",
    "    def __init__(self, random_state=None):\n",
    "        \n",
    "        self._random_state = random_state\n",
    "        self._causal_order = None\n",
    "        self._adjacency_matrix = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X):\n",
    "        \"\"\"Subclasses should implement this method!\n",
    "        Fit the model to X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns the instance itself.\n",
    "        \"\"\"\n",
    "\n",
    "    def estimate_total_effect(self, X, from_index, to_index):\n",
    "        # Check parameters\n",
    "        X = check_array(X)\n",
    "\n",
    "        # from_index + parents indices\n",
    "        parents = np.where(np.abs(self.adjacency_matrix_[from_index]) > 0)[0].tolist()\n",
    "        predictors = [from_index]\n",
    "        predictors.extend(parents)\n",
    "\n",
    "        # estimate total effect by Adaptive Lasso\n",
    "        coef = self._predict_adaptive_lasso(X, predictors, to_index)\n",
    "        return coef[0]\n",
    "\n",
    "    def _predict_adaptive_lasso(self, X, predictors, target, gamma=1.0):\n",
    "        \n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X[:, predictors], X[:, target])\n",
    "        weight = np.power(np.abs(lr.coef_), gamma)\n",
    "        reg = LassoLarsIC(criterion='bic')\n",
    "        reg.fit(X[:, predictors] * weight, X[:, target])\n",
    "        return reg.coef_ * weight\n",
    "\n",
    "    def _estimate_adjacency_matrix(self, X):\n",
    "        \n",
    "        B = np.zeros([X.shape[1], X.shape[1]], dtype='float64')\n",
    "        for i in range(1, len(self._causal_order)):\n",
    "            coef = self._predict_adaptive_lasso(\n",
    "                X, self._causal_order[:i], self._causal_order[i])\n",
    "            B[self._causal_order[i], self._causal_order[:i]] = coef\n",
    "\n",
    "        self._adjacency_matrix = B\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def causal_order_(self):\n",
    "        \n",
    "        return self._causal_order\n",
    "\n",
    "    @property\n",
    "    def adjacency_matrix_(self):\n",
    "        \n",
    "        return self._adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import scale\n",
    "\"\"\"\n",
    "\"_mutual_information\" used in the Tkernel calculation should be selected \n",
    "according to the quantum kernel calculation method to use\n",
    "\"\"\"\n",
    "class qLiNGAM(_BaseLiNGAM):\n",
    "\n",
    "    def __init__(self, random_state=None, prior_knowledge=None, measure='pwling'):\n",
    "        \n",
    "        super().__init__(random_state)\n",
    "        self._prior_knowledge = prior_knowledge\n",
    "        self._measure = measure\n",
    "\n",
    "    def fit(self, X):\n",
    "        \n",
    "        # Check parameters\n",
    "        X = check_array(X)\n",
    "        # number of variables\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self._prior_knowledge is not None:\n",
    "            self._Aknw = check_array(self._prior_knowledge)\n",
    "            self._Aknw = np.where(self._Aknw < 0, np.nan, self._Aknw)\n",
    "            if (n_features, n_features) != self._Aknw.shape:\n",
    "                raise ValueError('The shape of prior knowledge must be (n_features, n_features)')\n",
    "        else:\n",
    "            self._Aknw = None\n",
    "\n",
    "        # Causal discovery\n",
    "        U = np.arange(n_features)\n",
    "        K = []\n",
    "        X_ = np.copy(X)\n",
    "        if self._measure == 'kernel':\n",
    "            X_ = scale(X_)\n",
    "\n",
    "        for _ in range(n_features):\n",
    "            if self._measure == 'kernel':\n",
    "                m = self._search_causal_order_kernel(X_, U)\n",
    "            else:\n",
    "                m = self._search_causal_order(X_, U)\n",
    "            for i in U:\n",
    "                if i != m:\n",
    "                    X_[:, i] = self._residual(X_[:, i], X_[:, m])\n",
    "            K.append(m)\n",
    "            U = U[U != m]\n",
    "\n",
    "        self._causal_order = K\n",
    "        return self._estimate_adjacency_matrix(X)\n",
    "\n",
    "    def _residual(self, xi, xj):\n",
    "        \"\"\"The residual when xi is regressed on xj.\"\"\"\n",
    "        return xi - (np.cov(xi, xj)[0, 1] / np.var(xj)) * xj\n",
    "\n",
    "    def _search_candidate(self, U):\n",
    "        \"\"\" Search for candidate features \"\"\"\n",
    "        # If no prior knowledge is specified, nothing to do.\n",
    "        if self._Aknw is None:\n",
    "            return U, []\n",
    "\n",
    "        # Find exogenous features\n",
    "        Uc = []\n",
    "        for j in U:\n",
    "            index = U[U != j]\n",
    "            if self._Aknw[j][index].sum() == 0:\n",
    "                Uc.append(j)\n",
    "\n",
    "        # Find endogenous features, and then find candidate features\n",
    "        if len(Uc) == 0:\n",
    "            U_end = []\n",
    "            for j in U:\n",
    "                index = U[U != j]\n",
    "                if np.nansum(self._Aknw[j][index]) > 0:\n",
    "                    U_end.append(j)\n",
    "\n",
    "            # Find sink features (original)\n",
    "            for i in U:\n",
    "                index = U[U != i]\n",
    "                if self._Aknw[index, i].sum() == 0:\n",
    "                    U_end.append(i)\n",
    "            Uc = [i for i in U if i not in set(U_end)]\n",
    "\n",
    "        # make V^(j)\n",
    "        Vj = []\n",
    "        for i in U:\n",
    "            if i in Uc:\n",
    "                continue\n",
    "            if self._Aknw[i][Uc].sum() == 0:\n",
    "                Vj.append(i)\n",
    "        return Uc, Vj\n",
    "    \n",
    "    def _mutual_information_quantum_cirq_INOCCO(self, x1, x2, param):\n",
    "        \"\"\"Calculate the mutual informations with INOCCO for quantum computing\"\"\"\n",
    "        \n",
    "        eps = 1e-6\n",
    "        n = len(x1)\n",
    "        K1 = quantum_kernel_cirq_ring(bn=5, n_samples=n, data_x=x1, depth=2)\n",
    "        \n",
    "        transformer = KernelCenterer().fit(K1)\n",
    "        K1_centered = transformer.transform(K1)\n",
    "        \n",
    "        K2 = quantum_kernel_cirq_ring(bn=5, n_samples=n, data_x=x2, depth=2)\n",
    "        \n",
    "        transformer = KernelCenterer().fit(K2)\n",
    "        K2_centered = transformer.transform(K2)\n",
    "        \n",
    "        K1_temp = K1_centered+n*eps*np.identity(n)\n",
    "        K2_temp = K2_centered+n*eps*np.identity(n)\n",
    "        \n",
    "        K1_r = K1_centered @ np.linalg.inv(K1_temp)\n",
    "        K2_r = K2_centered @ np.linalg.inv(K2_temp)\n",
    "        \n",
    "        return np.trace(K2_r @ K1_r)\n",
    "    \n",
    "    def _mutual_information_quantum_cirq_INOCCO_linear(self, x1, x2, param):\n",
    "        eps = 1e-6\n",
    "        n = len(x1)\n",
    "        K1 = quantum_kernel_cirq_linear(bn=4, n_samples=n, data_x=x1, depth=1)\n",
    "        \n",
    "        transformer = KernelCenterer().fit(K1)\n",
    "        K1_centered = transformer.transform(K1)\n",
    "        \n",
    "        K2 = quantum_kernel_cirq_linear(bn=4, n_samples=n, data_x=x2, depth=1)\n",
    "        \n",
    "        transformer = KernelCenterer().fit(K2)\n",
    "        K2_centered = transformer.transform(K2)\n",
    "        \n",
    "        K1_temp = K1_centered+n*eps*np.identity(n)\n",
    "        K2_temp = K2_centered+n*eps*np.identity(n)\n",
    "        \n",
    "        K1_r = K1_centered @ np.linalg.inv(K1_temp)\n",
    "        K2_r = K2_centered @ np.linalg.inv(K2_temp)\n",
    "        \n",
    "        return np.trace(K2_r @ K1_r)\n",
    "    \n",
    "    def _mutual_information_quantum_IBMQ_mitigated(self, x1, x2, param):\n",
    "        eps = 1e-6\n",
    "        n = len(x1)\n",
    "        K1 = quantum_kernel_qiskit_IBMQ_sep_mitigated(bn=4, n_samples=n, data_x=x1, depth=1)\n",
    "        \n",
    "        transformer = KernelCenterer().fit(K1)\n",
    "        K1_centered = transformer.transform(K1)\n",
    "        \n",
    "        K2 = quantum_kernel_qiskit_IBMQ_sep_mitigated(bn=4, n_samples=n, data_x=x2, depth=1)\n",
    "        \n",
    "        transformer = KernelCenterer().fit(K2)\n",
    "        K2_centered = transformer.transform(K2)\n",
    "        \n",
    "        K1_temp = K1_centered+n*eps*np.identity(n)\n",
    "        K2_temp = K2_centered+n*eps*np.identity(n)\n",
    "        \n",
    "        K1_r = K1_centered @ np.linalg.inv(K1_temp)\n",
    "        K2_r = K2_centered @ np.linalg.inv(K2_temp)\n",
    "        \n",
    "        return np.trace(K2_r @ K1_r)\n",
    "    \n",
    "    def _search_causal_order_kernel(self, X, U):\n",
    "        \"\"\"Search the causal ordering by kernel method.\"\"\"\n",
    "        Uc, Vj = self._search_candidate(U)\n",
    "        if len(Uc) == 1:\n",
    "            return Uc[0]\n",
    "\n",
    "        if X.shape[0] > 1000:\n",
    "            param = [2e-3, 0.5]\n",
    "        else:\n",
    "            param = [2e-2, 1.0]\n",
    "\n",
    "        Tkernels = []\n",
    "        for j in Uc:\n",
    "            Tkernel = 0\n",
    "            for i in U:\n",
    "                if i != j:\n",
    "                    ri_j = X[:, i] if j in Vj and i in Uc else self._residual(\n",
    "                        X[:, i], X[:, j])\n",
    "                    Tkernel += self._mutual_information_quantum_IBMQ_mitigated(X[:, j], ri_j, param)\n",
    "            Tkernels.append(Tkernel)\n",
    "\n",
    "        return Uc[np.argmin(Tkernels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation: Obtain real-world medical data\n",
    "UCI Heart Disease Data Set is available at the following URL (Data used is \"processed.cleveland.data\"): <br>\n",
    "https://archive.ics.uci.edu/ml/datasets/Heart+Disease <br>\n",
    "Pima Indians Diabetes Database is available at the following URL:<br>\n",
    "https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UCI Heart Disease Data Set\"\"\"\n",
    "#Get the data from the above URL and save it as heartdata\n",
    "heartdata_full = heartdata[['age','cp','exang']] #full version\n",
    "heartdata_short = heartdata_full.sample(n=100, random_state=0) #short version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pima Indians Diabetes Database\"\"\"\n",
    "#Get the data from the above URL and save it as diabetesdata\n",
    "diabetesdata[['BloodPressure','Glucose','Insulin','BMI']] = diabetesdata[['BloodPressure','Glucose','Insulin','BMI']].replace(0, np.NaN)\n",
    "diabetesdata_new=diabetesdata.dropna()\n",
    "diabetesdata_full = diabetesdata_new[['Age','Insulin','Glucose']] #full version\n",
    "diabetesdata_short = diabetesdata_full.sample(n=100, random_state=0) #short version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1 #Number of experiments\n",
    "model_mass = np.empty([index, 3, 3])\n",
    "model_result = list() #list to put correct or incorrect answers\n",
    "for i in range(index):\n",
    "    np.random.seed(i)\n",
    "    n = 100\n",
    "    e = lambda n: np.random.laplace(0, 1, n)\n",
    "    x0 = e(n)\n",
    "    x1 = 0.3*x0 + e(n)\n",
    "    x2 = 0.3*x1 + 0.3*x0 + e(n)\n",
    "    X = pd.DataFrame(np.array([x0, x1, x2]).T ,columns=['x0', 'x1', 'x2'])\n",
    "    model_quantum = qLiNGAM(measure='kernel')\n",
    "    model_quantum.fit(X)\n",
    "    model_mass[i] = model_quantum.adjacency_matrix_\n",
    "    model_result.append(1) if np.sum(np.ceil(np.tril(model_quantum.adjacency_matrix_)))==3 else model_result.append(0)\n",
    "print(sum(model_result))\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with real-world medical data: Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Need to change qLiNGAM according to the quantum kernel to be implemented\"\"\"\n",
    "model_quantum = qLiNGAM(measure='kernel')\n",
    "model_quantum.fit(heartdata_short)\n",
    "print(model_quantum.adjacency_matrix_)\n",
    "print(heartdata_short.columns)\n",
    "make_dot(model_quantum.adjacency_matrix_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with real-world medical data: Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Need to change qLiNGAM according to the quantum kernel to be implemented\"\"\"\n",
    "model_quantum = qLiNGAM(measure='kernel')\n",
    "model_quantum.fit(diabetesdata_short)\n",
    "print(model_quantum.adjacency_matrix_)\n",
    "print(diabetesdata_short.columns)\n",
    "make_dot(model_quantum.adjacency_matrix_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
